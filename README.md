# Chat with Websites using LangChain

A Python application that lets you **chat with any website** using **LangChain** and LLMs (e.g., OpenAIâ€™s GPT models). This tool extracts and summarizes information from websites in response to your queries â€” making it easy to interact with live web content using natural language.

Powered by LangChain and Retrievalâ€‘Augmented Generation (RAG) techniques.

---

## ğŸš€ Features

- ğŸ•¸ï¸ Website Interaction â€” Retrieve and parse content directly from any URL.
- ğŸ§  LangChain Integration â€” Use LangChain to build the query pipeline and LLM interface.
- ğŸ’¬ Conversational Chat â€” Ask questions about a website and get concise answers.
- ğŸ”‘ OpenAI Support â€” Works with OpenAI models (GPT-3.5, GPT-4, etc.).
- ğŸ“œ Simple UI/CLI â€” Easy local interaction through Python scripts or a basic interface.

---

## ğŸ“¦ Installation

### ğŸ§° Prerequisites

- Python 3.8+
- An OpenAI API key

### ğŸ”½ Clone the repo

```bash
git clone https://github.com/Abdul770562/Chat-with-Websites-using-Langchain.git
cd Chat-with-Websites-using-Langchain
```

### ğŸ“¥ Install dependencies

```bash
pip install -r requirements.txt
```

### ğŸ”§ Setup

Create a `.env` file in the project root (copy from an example file if provided) and add your OpenAI key:

```env
OPENAI_API_KEY=your_openai_api_key_here
```

Make sure dependencies are installed and the `.env` file is configured.

---

## ğŸŸ¢ Usage

### ğŸ—¨ï¸ Chat from Terminal

Run the main script:

```bash
python src/main.py
```

You will be prompted to enter a website URL and then ask questions about the site:

Example session:

```text
Enter Website URL: https://example.com
Ask your question: What is this site about?
```

The bot will extract and summarize the answer for you.

---

## ğŸ” How It Works (RAG)

This application uses a Retrievalâ€‘Augmented Generation pipeline:

1. Fetch website content (HTML/text).
2. Extract and split text into chunks.
3. Use embeddings to index the data.
4. Query the vector store to find relevant information.
5. Use an LLM to generate responses based on the retrieved context.

---

## ğŸ› ï¸ Customization

- Change LLM models â€” switch between GPTâ€‘3.5 and GPTâ€‘4 (or other models supported by LangChain).
- Improve parsing â€” integrate custom HTML extractors or advanced loaders.
- Add vectorstores â€” use Redis, Chroma, Weaviate, etc., instead of the default.

---

## ğŸ§‘â€ğŸ¤â€ğŸ§‘ Contributing

Contributions are welcome! You can:

- Fix bugs
- Improve parsing logic
- Add new features (UI, better loaders)

Please open an issue or submit a pull request.

---

## ğŸ“œ License

This project is open source and available under the MIT License.

---

If you find this project helpful, please give it a star! â­
